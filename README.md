# 10 Days NLP Challenge

Google I/O samples


https://github.com/GoogleCloudPlatform/ai-platform-text-classifier-shap

>> Day 1 & Day 2: Basic NLP and semantic analysis

Intellipaat: Natural Language Processing (NLP) Tutorial | NLP Training
https://www.youtube.com/watch?v=KVxIx8f_VpM

ODSC: Understanding Unstructured Data with Language Models - Alex Peattie
https://www.youtube.com/watch?time_continue=37&v=4fMwu7K3HmQ

>> Day 3: Topic modeling

https://github.com/atulsinghphd/NLP/blob/master/TopicModelingUsingLDA.ipynb

https://github.com/moorissa/nmf_nyt

https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/

https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24
https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5333320/

Guided LDA : https://github.com/NThakur20/GuidedLDA

Bhargav Srinivasa Desikan - Topic Modelling with Gensim
https://www.youtube.com/watch?v=KZkLmN1Bzok
https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling_unrun.ipynb

Text Analysis https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/text_analysis_tutorial_unrun.ipynb

https://www.youtube.com/watch?v=ZkAFJwi-G98

Evaluation

https://towardsdatascience.com/metrics-for-evaluating-machine-learning-classification-models-python-example-59b905e079a5

>> Day 4: Predict next word 

https://github.com/seyedsaeidmasoumzadeh/Predict-next-word

https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/

Patrick Harrison: Modern NLP in Python | PyData DC 2016 ( 1:11:00)
https://www.youtube.com/watch?v=6zm9NC9uRkk

https://towardsdatascience.com/building-a-next-word-predictor-in-tensorflow-e7e681d4f03f
https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c

>> Day 5: Word Embeddings - word2Vec, Glove, NGram

Minsuk Heo : Word2Vec (introduce and tensorflow implementation)
https://www.youtube.com/watch?v=64qSgA66P-8
https://github.com/minsuk-heo/python_tutorial/blob/master/data_science/nlp/word2vec_tensorflow.ipynb

https://skymind.ai/wiki/word2vec

https://datascience.stackexchange.com/questions/9785/predicting-a-word-using-word2vec-model

https://www.guru99.com/word-embedding-word2vec.html

https://github.com/tensorflow/docs/blob/master/site/en/tutorials/representation/word2vec.md

>> Day 6: LSTM, IF-TDF, Naive Bayes

TODO

>> Day 7: Computer vision - CNN

TODO

https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html

https://ahmedbesbes.com/automate-the-diagnosis-of-knee-injuries-with-deep-learning-part-1-an-overview-of-the-mrnet-dataset.html

https://ahmedbesbes.com/automate-the-diagnosis-of-knee-injuries-with-deep-learning-part-2-building-an-acl-tear-classifier.html

https://ahmedbesbes.com/automate-the-diagnosis-of-knee-injuries-with-deep-learning-part-3-interpret-models-predictions.html


>> Day 8: Transfer learning

TODO

A neural network is trained on a data. This network gains knowledge from this data, which is compiled as “weights” of the network. These weights can be extracted and then transferred to any other neural network. Instead of training the other neural network from scratch, we “transfer” the learned features.

>> Day 9: Pretrained models - BERT, ElMo, ULMFit

TODO

>> Day 10: Research paper

TODO

>> Aditional references

A Friendly Introduction to Machine Learning
https://www.youtube.com/watch?v=IpGxLWOIZy4

But what is a Neural Network? 
https://www.youtube.com/watch?v=aircAruvnKk&t=5s

Gradient descent, how neural networks learn 
https://www.youtube.com/watch?v=IHZwWFHWa-w&t=59s

What is backpropagation really doing?
https://www.youtube.com/watch?v=Ilg3gGewQ5U

Embed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models
https://explosion.ai/blog/deep-learning-formula-nlp
